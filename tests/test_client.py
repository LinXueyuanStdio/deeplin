"""
ç¤ºä¾‹ï¼šä½¿ç”¨ OpenAI å®¢æˆ·ç«¯è°ƒç”¨ FastAPI ä»£ç†æœåŠ¡å™¨
"""
import asyncio
import openai

# å›ºå®šçš„ API keyï¼ˆä¸æœåŠ¡å™¨ä¸­å®šä¹‰çš„ä¸€è‡´ï¼‰
API_KEY = "sk-deeplin-fastapi-proxy-key-12345"

# æœåŠ¡å™¨åœ°å€
BASE_URL = "http://localhost:8000/v1"

async def test_openai_client():
    """æµ‹è¯• OpenAI å®¢æˆ·ç«¯è°ƒç”¨"""

    # åˆ›å»º OpenAI å¼‚æ­¥å®¢æˆ·ç«¯
    client = openai.AsyncOpenAI(
        api_key=API_KEY,
        base_url=BASE_URL
    )

    try:
        # 1. åˆ—å‡ºå¯ç”¨æ¨¡å‹
        print("ğŸ” è·å–å¯ç”¨æ¨¡å‹...")
        models = await client.models.list()
        print(f"å¯ç”¨æ¨¡å‹æ•°é‡: {len(models.data)}")
        for model in models.data[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæ¨¡å‹
            print(f"  - {model.id} ({model.owned_by})")

        # 2. åŸºæœ¬èŠå¤©å®Œæˆ
        print("\nğŸ’¬ åŸºæœ¬èŠå¤©å®Œæˆ...")
        response = await client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
            ],
            max_tokens=100
        )
        print(f"å›å¤: {response.choices[0].message.content}")

        # 3. æµå¼èŠå¤©å®Œæˆ
        print("\nğŸŒŠ æµå¼èŠå¤©å®Œæˆ...")
        stream = await client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯æè¿°äººå·¥æ™ºèƒ½çš„æœªæ¥ã€‚"}
            ],
            max_tokens=50,
            stream=True
        )

        print("æµå¼å›å¤: ", end="", flush=True)
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end="", flush=True)
        print()  # æ¢è¡Œ

        # 4. å·¥å…·è°ƒç”¨ç¤ºä¾‹
        print("\nğŸ”§ å·¥å…·è°ƒç”¨ç¤ºä¾‹...")
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "city": {
                                "type": "string",
                                "description": "åŸå¸‚åç§°"
                            }
                        },
                        "required": ["city"]
                    }
                }
            }
        ]

        response = await client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
            ],
            tools=tools,
            max_tokens=100
        )

        if response.choices[0].message.tool_calls:
            print("æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨:")
            for tool_call in response.choices[0].message.tool_calls:
                print(f"  - {tool_call.function.name}: {tool_call.function.arguments}")
        else:
            print(f"æ™®é€šå›å¤: {response.choices[0].message.content}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

    finally:
        await client.close()

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯• OpenAI å®¢æˆ·ç«¯...")
    asyncio.run(test_openai_client())
    print("âœ… æµ‹è¯•å®Œæˆ!")
